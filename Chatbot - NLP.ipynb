{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('C:/Users/ksa/Downloads/original/UPDATED_NLP_COURSE/06-Deep-Learning/train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('C:/Users/ksa/Downloads/original/UPDATED_NLP_COURSE/06-Deep-Learning/test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'grabbed': 1,\n",
       " 'is': 2,\n",
       " 'back': 3,\n",
       " '?': 4,\n",
       " 'there': 5,\n",
       " 'yes': 6,\n",
       " 'to': 7,\n",
       " 'milk': 8,\n",
       " 'got': 9,\n",
       " 'football': 10,\n",
       " 'dropped': 11,\n",
       " 'kitchen': 12,\n",
       " 'the': 13,\n",
       " 'left': 14,\n",
       " 'took': 15,\n",
       " 'office': 16,\n",
       " 'put': 17,\n",
       " 'sandra': 18,\n",
       " 'in': 19,\n",
       " 'hallway': 20,\n",
       " 'no': 21,\n",
       " 'up': 22,\n",
       " 'journeyed': 23,\n",
       " 'down': 24,\n",
       " 'garden': 25,\n",
       " 'bedroom': 26,\n",
       " 'discarded': 27,\n",
       " 'travelled': 28,\n",
       " 'moved': 29,\n",
       " 'went': 30,\n",
       " 'mary': 31,\n",
       " 'apple': 32,\n",
       " 'john': 33,\n",
       " '.': 34,\n",
       " 'bathroom': 35,\n",
       " 'daniel': 36,\n",
       " 'picked': 37}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 13, 26, 34],\n",
       "       [ 0,  0,  0, ..., 13, 20, 34],\n",
       "       [ 0,  0,  0, ..., 13, 35, 34],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 13, 26, 34],\n",
       "       [ 0,  0,  0, ...,  8,  5, 34],\n",
       "       [ 0,  0,  0, ..., 32,  5, 34]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 503.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "1. Build the Network:\n",
    "\n",
    "    a) Input Encoder M    \n",
    "    b) Input Encoder C    \n",
    "    c) Question Encoder\n",
    "    \n",
    "    \n",
    "2. Complete the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from keras.layers import add, dot, concatenate\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1-  Create placeholders for both the inputs - story and questions\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 2- VOCAB\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENCODERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Input Encoder m with output dim = 64\n",
    "# Create INPUT ENCODER M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim = vocab_size, output_dim = 64))\n",
    "\n",
    "# Dropout layer - turns off percentage of neurons during training - so 0.5 means 50% of neurons are random turned off\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3 - Input Encoder c with output dim = max_question_len\n",
    "# Create INPUT ENCODER M\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim = vocab_size, output_dim = max_question_len))\n",
    "\n",
    "# Dropout layer - turns off percentage of neurons during training - so 0.5 means 50% of neurons are random turned off\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, max_question_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time to pass the placeholders (input sequence and question) through the encoders\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# match the question with the input (search for question match) and then do a dot product\n",
    "match = dot([input_encoded_m, question_encoded], axes = (2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])\n",
    "response = Permute((2,1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_2/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the final model\n",
    "Model = Model([input_sequence, question], answer)\n",
    "Model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_3 (Sequential)       multiple             2432        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_6 (Sequential)       (None, 6, 64)        2432        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_3[2][0]               \n",
      "                                                                 sequential_6[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       multiple             228         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_4[3][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 6, 64)        2432        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_7[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,162\n",
      "Trainable params: 41,162\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "Model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\ksa\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/120\n",
      "10000/10000 [==============================] - 6s 588us/step - loss: 0.9122 - accuracy: 0.4902 - val_loss: 0.7007 - val_accuracy: 0.4970\n",
      "Epoch 2/120\n",
      "10000/10000 [==============================] - 5s 461us/step - loss: 0.7041 - accuracy: 0.4998 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "10000/10000 [==============================] - 6s 581us/step - loss: 0.6958 - accuracy: 0.5034 - val_loss: 0.6968 - val_accuracy: 0.4970\n",
      "Epoch 4/120\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.6952 - accuracy: 0.4947 - val_loss: 0.6932 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.6945 - accuracy: 0.5035 - val_loss: 0.6935 - val_accuracy: 0.4970\n",
      "Epoch 6/120\n",
      "10000/10000 [==============================] - 5s 463us/step - loss: 0.6942 - accuracy: 0.5016 - val_loss: 0.6933 - val_accuracy: 0.4820\n",
      "Epoch 7/120\n",
      "10000/10000 [==============================] - 5s 483us/step - loss: 0.6943 - accuracy: 0.5080 - val_loss: 0.6964 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.6945 - accuracy: 0.5029 - val_loss: 0.6945 - val_accuracy: 0.4870\n",
      "Epoch 9/120\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.6926 - accuracy: 0.5182 - val_loss: 0.6928 - val_accuracy: 0.5210\n",
      "Epoch 10/120\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.6640 - accuracy: 0.6068 - val_loss: 0.6268 - val_accuracy: 0.6900\n",
      "Epoch 11/120\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.5869 - accuracy: 0.7087 - val_loss: 0.5267 - val_accuracy: 0.7400\n",
      "Epoch 12/120\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.4913 - accuracy: 0.7755 - val_loss: 0.4354 - val_accuracy: 0.8050\n",
      "Epoch 13/120\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.4416 - accuracy: 0.8110 - val_loss: 0.4212 - val_accuracy: 0.8160\n",
      "Epoch 14/120\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.4092 - accuracy: 0.8328 - val_loss: 0.4054 - val_accuracy: 0.8230\n",
      "Epoch 15/120\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.3960 - accuracy: 0.8375 - val_loss: 0.4243 - val_accuracy: 0.8400\n",
      "Epoch 16/120\n",
      "10000/10000 [==============================] - 5s 490us/step - loss: 0.3770 - accuracy: 0.8448 - val_loss: 0.3878 - val_accuracy: 0.8450\n",
      "Epoch 17/120\n",
      "10000/10000 [==============================] - 5s 548us/step - loss: 0.3665 - accuracy: 0.8484 - val_loss: 0.3896 - val_accuracy: 0.8490\n",
      "Epoch 18/120\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.3556 - accuracy: 0.8546 - val_loss: 0.3694 - val_accuracy: 0.8330\n",
      "Epoch 19/120\n",
      "10000/10000 [==============================] - 5s 509us/step - loss: 0.3429 - accuracy: 0.8557 - val_loss: 0.3563 - val_accuracy: 0.8430\n",
      "Epoch 20/120\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.3340 - accuracy: 0.8598 - val_loss: 0.3737 - val_accuracy: 0.8460\n",
      "Epoch 21/120\n",
      "10000/10000 [==============================] - 5s 478us/step - loss: 0.3257 - accuracy: 0.8621 - val_loss: 0.3456 - val_accuracy: 0.8410\n",
      "Epoch 22/120\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.3228 - accuracy: 0.8608 - val_loss: 0.3545 - val_accuracy: 0.8260\n",
      "Epoch 23/120\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.3174 - accuracy: 0.8659 - val_loss: 0.3401 - val_accuracy: 0.8460\n",
      "Epoch 24/120\n",
      "10000/10000 [==============================] - 5s 473us/step - loss: 0.3145 - accuracy: 0.8635 - val_loss: 0.3525 - val_accuracy: 0.8480\n",
      "Epoch 25/120\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.3088 - accuracy: 0.8672 - val_loss: 0.3311 - val_accuracy: 0.8450\n",
      "Epoch 26/120\n",
      "10000/10000 [==============================] - 5s 469us/step - loss: 0.3068 - accuracy: 0.8659 - val_loss: 0.3309 - val_accuracy: 0.8490\n",
      "Epoch 27/120\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.3009 - accuracy: 0.8665 - val_loss: 0.3376 - val_accuracy: 0.8460\n",
      "Epoch 28/120\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.3037 - accuracy: 0.8673 - val_loss: 0.3400 - val_accuracy: 0.8500\n",
      "Epoch 29/120\n",
      "10000/10000 [==============================] - 4s 439us/step - loss: 0.3016 - accuracy: 0.8663 - val_loss: 0.3365 - val_accuracy: 0.8390\n",
      "Epoch 30/120\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.2983 - accuracy: 0.8690 - val_loss: 0.3292 - val_accuracy: 0.8430\n",
      "Epoch 31/120\n",
      "10000/10000 [==============================] - 5s 512us/step - loss: 0.2956 - accuracy: 0.8672 - val_loss: 0.3350 - val_accuracy: 0.8420\n",
      "Epoch 32/120\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.2960 - accuracy: 0.8682 - val_loss: 0.3497 - val_accuracy: 0.8390\n",
      "Epoch 33/120\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.2936 - accuracy: 0.8694 - val_loss: 0.3492 - val_accuracy: 0.8410\n",
      "Epoch 34/120\n",
      "10000/10000 [==============================] - 4s 446us/step - loss: 0.2933 - accuracy: 0.8681 - val_loss: 0.3378 - val_accuracy: 0.8440\n",
      "Epoch 35/120\n",
      "10000/10000 [==============================] - 6s 558us/step - loss: 0.2940 - accuracy: 0.8681 - val_loss: 0.3398 - val_accuracy: 0.8420\n",
      "Epoch 36/120\n",
      "10000/10000 [==============================] - 6s 584us/step - loss: 0.2884 - accuracy: 0.8724 - val_loss: 0.3537 - val_accuracy: 0.8430\n",
      "Epoch 37/120\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.2871 - accuracy: 0.8735 - val_loss: 0.3636 - val_accuracy: 0.8340\n",
      "Epoch 38/120\n",
      "10000/10000 [==============================] - 6s 567us/step - loss: 0.2896 - accuracy: 0.8726 - val_loss: 0.3334 - val_accuracy: 0.8450\n",
      "Epoch 39/120\n",
      "10000/10000 [==============================] - 6s 642us/step - loss: 0.2860 - accuracy: 0.8711 - val_loss: 0.3428 - val_accuracy: 0.8290\n",
      "Epoch 40/120\n",
      "10000/10000 [==============================] - 5s 508us/step - loss: 0.2888 - accuracy: 0.8708 - val_loss: 0.3468 - val_accuracy: 0.8350\n",
      "Epoch 41/120\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.2899 - accuracy: 0.8719 - val_loss: 0.3487 - val_accuracy: 0.8390\n",
      "Epoch 42/120\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.2881 - accuracy: 0.8712 - val_loss: 0.3615 - val_accuracy: 0.8400\n",
      "Epoch 43/120\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.2839 - accuracy: 0.8733 - val_loss: 0.3592 - val_accuracy: 0.8290\n",
      "Epoch 44/120\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.2848 - accuracy: 0.8741 - val_loss: 0.3427 - val_accuracy: 0.8410\n",
      "Epoch 45/120\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.2839 - accuracy: 0.8728 - val_loss: 0.4015 - val_accuracy: 0.8330\n",
      "Epoch 46/120\n",
      "10000/10000 [==============================] - 6s 637us/step - loss: 0.2860 - accuracy: 0.8747 - val_loss: 0.3735 - val_accuracy: 0.8460\n",
      "Epoch 47/120\n",
      "10000/10000 [==============================] - 6s 635us/step - loss: 0.2809 - accuracy: 0.8753 - val_loss: 0.3410 - val_accuracy: 0.8370\n",
      "Epoch 48/120\n",
      "10000/10000 [==============================] - 6s 631us/step - loss: 0.2825 - accuracy: 0.8713 - val_loss: 0.3468 - val_accuracy: 0.8370\n",
      "Epoch 49/120\n",
      "10000/10000 [==============================] - 6s 626us/step - loss: 0.2800 - accuracy: 0.8763 - val_loss: 0.3440 - val_accuracy: 0.8380\n",
      "Epoch 50/120\n",
      "10000/10000 [==============================] - 6s 624us/step - loss: 0.2787 - accuracy: 0.8721 - val_loss: 0.3548 - val_accuracy: 0.8430\n",
      "Epoch 51/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 594us/step - loss: 0.2790 - accuracy: 0.8759 - val_loss: 0.3486 - val_accuracy: 0.8310\n",
      "Epoch 52/120\n",
      "10000/10000 [==============================] - 6s 644us/step - loss: 0.2800 - accuracy: 0.8753 - val_loss: 0.3701 - val_accuracy: 0.8370\n",
      "Epoch 53/120\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.2776 - accuracy: 0.8775 - val_loss: 0.3680 - val_accuracy: 0.8390\n",
      "Epoch 54/120\n",
      "10000/10000 [==============================] - 6s 583us/step - loss: 0.2767 - accuracy: 0.8768 - val_loss: 0.3619 - val_accuracy: 0.8360\n",
      "Epoch 55/120\n",
      "10000/10000 [==============================] - 5s 476us/step - loss: 0.2773 - accuracy: 0.8772 - val_loss: 0.3675 - val_accuracy: 0.8400\n",
      "Epoch 56/120\n",
      "10000/10000 [==============================] - 5s 499us/step - loss: 0.2734 - accuracy: 0.8783 - val_loss: 0.3700 - val_accuracy: 0.8370\n",
      "Epoch 57/120\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.2753 - accuracy: 0.8793 - val_loss: 0.3943 - val_accuracy: 0.8400\n",
      "Epoch 58/120\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.2698 - accuracy: 0.8816 - val_loss: 0.3985 - val_accuracy: 0.8320\n",
      "Epoch 59/120\n",
      "10000/10000 [==============================] - 5s 505us/step - loss: 0.2711 - accuracy: 0.8799 - val_loss: 0.3780 - val_accuracy: 0.8320\n",
      "Epoch 60/120\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.2699 - accuracy: 0.8796 - val_loss: 0.3744 - val_accuracy: 0.8250\n",
      "Epoch 61/120\n",
      "10000/10000 [==============================] - 5s 516us/step - loss: 0.2715 - accuracy: 0.8770 - val_loss: 0.3935 - val_accuracy: 0.8360\n",
      "Epoch 62/120\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.2726 - accuracy: 0.8793 - val_loss: 0.3591 - val_accuracy: 0.8290\n",
      "Epoch 63/120\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.2689 - accuracy: 0.8794 - val_loss: 0.3553 - val_accuracy: 0.8360\n",
      "Epoch 64/120\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.2710 - accuracy: 0.8817 - val_loss: 0.3888 - val_accuracy: 0.8380\n",
      "Epoch 65/120\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.2705 - accuracy: 0.8803 - val_loss: 0.3596 - val_accuracy: 0.8320\n",
      "Epoch 66/120\n",
      "10000/10000 [==============================] - 5s 475us/step - loss: 0.2707 - accuracy: 0.8807 - val_loss: 0.3801 - val_accuracy: 0.8340\n",
      "Epoch 67/120\n",
      "10000/10000 [==============================] - 4s 424us/step - loss: 0.2668 - accuracy: 0.8825 - val_loss: 0.3709 - val_accuracy: 0.8350\n",
      "Epoch 68/120\n",
      "10000/10000 [==============================] - 5s 455us/step - loss: 0.2673 - accuracy: 0.8797 - val_loss: 0.3802 - val_accuracy: 0.8310\n",
      "Epoch 69/120\n",
      "10000/10000 [==============================] - 5s 507us/step - loss: 0.2641 - accuracy: 0.8826 - val_loss: 0.3920 - val_accuracy: 0.8360\n",
      "Epoch 70/120\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.2698 - accuracy: 0.8821 - val_loss: 0.4014 - val_accuracy: 0.8320\n",
      "Epoch 71/120\n",
      "10000/10000 [==============================] - 4s 418us/step - loss: 0.2628 - accuracy: 0.8817 - val_loss: 0.3687 - val_accuracy: 0.8370\n",
      "Epoch 72/120\n",
      "10000/10000 [==============================] - 4s 429us/step - loss: 0.2618 - accuracy: 0.8828 - val_loss: 0.4150 - val_accuracy: 0.8400\n",
      "Epoch 73/120\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.2644 - accuracy: 0.8830 - val_loss: 0.4280 - val_accuracy: 0.8300\n",
      "Epoch 74/120\n",
      "10000/10000 [==============================] - 6s 551us/step - loss: 0.2619 - accuracy: 0.8837 - val_loss: 0.4345 - val_accuracy: 0.8340\n",
      "Epoch 75/120\n",
      "10000/10000 [==============================] - 6s 553us/step - loss: 0.2578 - accuracy: 0.8809 - val_loss: 0.3933 - val_accuracy: 0.8300\n",
      "Epoch 76/120\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.2579 - accuracy: 0.8837 - val_loss: 0.3855 - val_accuracy: 0.8310\n",
      "Epoch 77/120\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.2590 - accuracy: 0.8876 - val_loss: 0.3972 - val_accuracy: 0.8280\n",
      "Epoch 78/120\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.2585 - accuracy: 0.8851 - val_loss: 0.4113 - val_accuracy: 0.8290\n",
      "Epoch 79/120\n",
      "10000/10000 [==============================] - 5s 515us/step - loss: 0.2577 - accuracy: 0.8849 - val_loss: 0.3992 - val_accuracy: 0.8220\n",
      "Epoch 80/120\n",
      "10000/10000 [==============================] - 5s 485us/step - loss: 0.2546 - accuracy: 0.8862 - val_loss: 0.3928 - val_accuracy: 0.8230\n",
      "Epoch 81/120\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.2613 - accuracy: 0.8861 - val_loss: 0.4631 - val_accuracy: 0.8320\n",
      "Epoch 82/120\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.2542 - accuracy: 0.8840 - val_loss: 0.4416 - val_accuracy: 0.8300\n",
      "Epoch 83/120\n",
      "10000/10000 [==============================] - 5s 534us/step - loss: 0.2559 - accuracy: 0.8874 - val_loss: 0.4384 - val_accuracy: 0.8270\n",
      "Epoch 84/120\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.2511 - accuracy: 0.8876 - val_loss: 0.4013 - val_accuracy: 0.8330\n",
      "Epoch 85/120\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.2497 - accuracy: 0.8890 - val_loss: 0.3696 - val_accuracy: 0.8300\n",
      "Epoch 86/120\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.2466 - accuracy: 0.8905 - val_loss: 0.4159 - val_accuracy: 0.8260\n",
      "Epoch 87/120\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.2506 - accuracy: 0.8876 - val_loss: 0.5015 - val_accuracy: 0.8250\n",
      "Epoch 88/120\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.2485 - accuracy: 0.8897 - val_loss: 0.4781 - val_accuracy: 0.8290\n",
      "Epoch 89/120\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.2432 - accuracy: 0.8909 - val_loss: 0.4734 - val_accuracy: 0.8240\n",
      "Epoch 90/120\n",
      "10000/10000 [==============================] - 5s 510us/step - loss: 0.2486 - accuracy: 0.8881 - val_loss: 0.4703 - val_accuracy: 0.8270\n",
      "Epoch 91/120\n",
      "10000/10000 [==============================] - 5s 496us/step - loss: 0.2432 - accuracy: 0.8898 - val_loss: 0.4051 - val_accuracy: 0.8250\n",
      "Epoch 92/120\n",
      "10000/10000 [==============================] - 5s 487us/step - loss: 0.2422 - accuracy: 0.8920 - val_loss: 0.4610 - val_accuracy: 0.8340\n",
      "Epoch 93/120\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.2377 - accuracy: 0.8932 - val_loss: 0.5258 - val_accuracy: 0.8250\n",
      "Epoch 94/120\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.2442 - accuracy: 0.8908 - val_loss: 0.4627 - val_accuracy: 0.8290\n",
      "Epoch 95/120\n",
      "10000/10000 [==============================] - 5s 474us/step - loss: 0.2440 - accuracy: 0.8929 - val_loss: 0.4597 - val_accuracy: 0.8250\n",
      "Epoch 96/120\n",
      "10000/10000 [==============================] - 5s 497us/step - loss: 0.2377 - accuracy: 0.8914 - val_loss: 0.5452 - val_accuracy: 0.8190\n",
      "Epoch 97/120\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.2333 - accuracy: 0.8950 - val_loss: 0.5253 - val_accuracy: 0.8270\n",
      "Epoch 98/120\n",
      "10000/10000 [==============================] - 5s 486us/step - loss: 0.2406 - accuracy: 0.8932 - val_loss: 0.4643 - val_accuracy: 0.8280\n",
      "Epoch 99/120\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.2377 - accuracy: 0.8921 - val_loss: 0.4620 - val_accuracy: 0.8280\n",
      "Epoch 100/120\n",
      "10000/10000 [==============================] - 5s 477us/step - loss: 0.2297 - accuracy: 0.8965 - val_loss: 0.4922 - val_accuracy: 0.8250\n",
      "Epoch 101/120\n",
      "10000/10000 [==============================] - 5s 492us/step - loss: 0.2338 - accuracy: 0.8957 - val_loss: 0.4862 - val_accuracy: 0.8260\n",
      "Epoch 102/120\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.2320 - accuracy: 0.8966 - val_loss: 0.6162 - val_accuracy: 0.8340\n",
      "Epoch 103/120\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.2277 - accuracy: 0.8942 - val_loss: 0.4614 - val_accuracy: 0.8230\n",
      "Epoch 104/120\n",
      "10000/10000 [==============================] - 5s 489us/step - loss: 0.2280 - accuracy: 0.8965 - val_loss: 0.5133 - val_accuracy: 0.8240\n",
      "Epoch 105/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 577us/step - loss: 0.2305 - accuracy: 0.8965 - val_loss: 0.4697 - val_accuracy: 0.8270\n",
      "Epoch 106/120\n",
      "10000/10000 [==============================] - 6s 552us/step - loss: 0.2257 - accuracy: 0.8983 - val_loss: 0.5072 - val_accuracy: 0.8210\n",
      "Epoch 107/120\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.2284 - accuracy: 0.8971 - val_loss: 0.4851 - val_accuracy: 0.8360\n",
      "Epoch 108/120\n",
      "10000/10000 [==============================] - 5s 482us/step - loss: 0.2227 - accuracy: 0.8985 - val_loss: 0.5391 - val_accuracy: 0.8260\n",
      "Epoch 109/120\n",
      "10000/10000 [==============================] - 5s 502us/step - loss: 0.2241 - accuracy: 0.9006 - val_loss: 0.4836 - val_accuracy: 0.8240\n",
      "Epoch 110/120\n",
      "10000/10000 [==============================] - 5s 504us/step - loss: 0.2257 - accuracy: 0.9015 - val_loss: 0.4995 - val_accuracy: 0.8260\n",
      "Epoch 111/120\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.2150 - accuracy: 0.8995 - val_loss: 0.5342 - val_accuracy: 0.8230\n",
      "Epoch 112/120\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.2168 - accuracy: 0.9034 - val_loss: 0.5375 - val_accuracy: 0.8230\n",
      "Epoch 113/120\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.2215 - accuracy: 0.9037 - val_loss: 0.5175 - val_accuracy: 0.8230\n",
      "Epoch 114/120\n",
      "10000/10000 [==============================] - 6s 559us/step - loss: 0.2190 - accuracy: 0.9019 - val_loss: 0.5423 - val_accuracy: 0.8220\n",
      "Epoch 115/120\n",
      "10000/10000 [==============================] - 5s 549us/step - loss: 0.2166 - accuracy: 0.9038 - val_loss: 0.5566 - val_accuracy: 0.8240\n",
      "Epoch 116/120\n",
      "10000/10000 [==============================] - 5s 506us/step - loss: 0.2216 - accuracy: 0.9014 - val_loss: 0.5710 - val_accuracy: 0.8210\n",
      "Epoch 117/120\n",
      "10000/10000 [==============================] - 5s 491us/step - loss: 0.2118 - accuracy: 0.9062 - val_loss: 0.6613 - val_accuracy: 0.8270\n",
      "Epoch 118/120\n",
      "10000/10000 [==============================] - 5s 501us/step - loss: 0.2119 - accuracy: 0.9036 - val_loss: 0.5360 - val_accuracy: 0.8280\n",
      "Epoch 119/120\n",
      "10000/10000 [==============================] - 5s 468us/step - loss: 0.2119 - accuracy: 0.9071 - val_loss: 0.5918 - val_accuracy: 0.8270\n",
      "Epoch 120/120\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.2079 - accuracy: 0.9088 - val_loss: 0.6045 - val_accuracy: 0.8240\n"
     ]
    }
   ],
   "source": [
    "# Model train\n",
    "history = Model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['val_loss', 'val_accuracy', 'loss', 'accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3dd3xUVdrA8d+TSe+kUBOqVAtFRMDewd7Wgq6r7oplXcu6Rbe4u77rrvuur72vunawKyoWVBRF6SBVICKQUEISSM9MZibn/ePckCEkMJAMyU2e7+fDx7l37r1z7kw8zz3POfdcMcaglFKq84pq6wIopZRqWxoIlFKqk9NAoJRSnZwGAqWU6uQ0ECilVCengUAppTo5DQSqUxGR50Tk72Fuu15ETo50mZRqaxoIlFKqk9NAoJQLiUh0W5dBdRwaCFS746RkfisiS0WkSkSeEZFuIvKhiFSIyKci0iVk+7NFZIWIlIrIFyIyNOS9kSKyyNnvVSC+0WedKSJLnH2/EZHDwizjGSKyWETKRSRfRP7a6P2jneOVOu9f6axPEJH/E5ENIlImIl87644XkYImvoeTndd/FZE3ROQlESkHrhSRMSLyrfMZW0TkERGJDdn/YBGZISLbRaRQRP4gIt1FpFpEMkO2O1xEikQkJpxzVx2PBgLVXl0AnAIMAs4CPgT+AGRh/25vAhCRQcAU4BYgG5gOvCcisU6l+A7wIpABvO4cF2ffUcCzwLVAJvAkME1E4sIoXxVwBZAOnAFcLyLnOsft7ZT3YadMI4Alzn73AocD450y/Q6oC/M7OQd4w/nMl4EgcKvznYwDTgJucMqQAnwKfAT0BA4CPjPGbAW+AC4KOe7lwFRjjD/McqgORgOBaq8eNsYUGmM2AV8Bc40xi40xPuBtYKSz3cXAB8aYGU5Fdi+QgK1oxwIxwAPGGL8x5g1gfshnXAM8aYyZa4wJGmOeB3zOfntkjPnCGLPMGFNnjFmKDUbHOW9fBnxqjJnifG6JMWaJiEQBVwM3G2M2OZ/5jXNO4fjWGPOO85k1xpiFxpg5xpiAMWY9NpDVl+FMYKsx5v+MMV5jTIUxZq7z3vPYyh8R8QCXYoOl6qQ0EKj2qjDkdU0Ty8nO657Ahvo3jDF1QD7Qy3lvk9l1ZsUNIa/7ALc5qZVSESkFcp399khEjhSRmU5KpQy4DntljnOMH5rYLQubmmrqvXDkNyrDIBF5X0S2Oumif4RRBoB3gWEi0h/b6iozxszbzzKpDkADgXK7zdgKHQAREWwluAnYAvRy1tXrHfI6H7jbGJMe8i/RGDMljM99BZgG5Bpj0oAngPrPyQcGNLFPMeBt5r0qIDHkPDzYtFKoxlMFPw58Dww0xqRiU2d7KwPGGC/wGrbl8lO0NdDpaSBQbvcacIaInOR0dt6GTe98A3wLBICbRCRaRM4HxoTs+x/gOufqXkQkyekETgnjc1OA7cYYr4iMASaFvPcycLKIXOR8bqaIjHBaK88C94lITxHxiMg4p09iDRDvfH4M8Cdgb30VKUA5UCkiQ4DrQ957H+guIreISJyIpIjIkSHvvwBcCZwNvBTG+aoOTAOBcjVjzGpsvvth7BX3WcBZxphaY0wtcD62wtuB7U94K2TfBdh+gkec9/OcbcNxA3CXiFQAd2IDUv1xNwKnY4PSdmxH8XDn7d8Ay7B9FduBfwFRxpgy55hPY1szVcAuo4ia8BtsAKrABrVXQ8pQgU37nAVsBdYCJ4S8PxvbSb3I6V9QnZjog2mU6pxE5HPgFWPM021dFtW2NBAo1QmJyBHADGwfR0Vbl0e1LU0NKdXJiMjz2HsMbtEgoEBbBEop1elpi0AppTo5101clZWVZfr27dvWxVBKKVdZuHBhsTGm8b0pgAsDQd++fVmwYEFbF0MppVxFRDY0956mhpRSqpPTQKCUUp2cBgKllOrkXNdH0BS/309BQQFer7etixJR8fHx5OTkEBOjzw9RSrWeDhEICgoKSElJoW/fvuw60WTHYYyhpKSEgoIC+vXr19bFUUp1IB0iNeT1esnMzOywQQBARMjMzOzwrR6l1IHXIQIB0KGDQL3OcI5KqQOvwwQCpZTqiIwxLN9Uxv0z1rBqS3lEPkMDQSsoLS3lscce2+f9Tj/9dEpLSyNQIqWU2+Rvr2ZDSdXO5dpAHY/OzOPof83kzIe/5qHP17Jgw46IfHZEO4tFZALwIOABnjbG3NPo/T7YJzZlYx/ScbkxZm8P42h36gPBDTfcsMv6YDCIx+Npdr/p06dHumhKqTZSG6ij0hegyhege1o8MZ6G6+7iSh+JsR4SY20V/OWaIm54aSHV/iATDu7OxEN78OjneawurODYQdncfNJAThzalazkvT20bv9ELBA4z1x9FPuUpAJgvohMM8asDNnsXuAFY8zzInIi8E/sM1Rd5fbbb+eHH35gxIgRxMTEkJycTI8ePViyZAkrV67k3HPPJT8/H6/Xy80338zkyZOBhukyKisrmThxIkcffTTffPMNvXr14t133yUhIaGNz0wptTdVvgAi7KzUt1fV8oe3lvHRiq07t0lPjOGUod0Y2C2ZT1YUsmDDDlLiornoiFx6pMXzzw+/Z1C3FI4blM3Lczfw4fKt9EyL5+krRnPysG4RP4dItgjGAHnGmHUAIjIVOAcIDQTDgFud1zOBd1r6oX97bwUrN7duHm1Yz1T+ctbBzb5/zz33sHz5cpYsWcIXX3zBGWecwfLly3cO83z22WfJyMigpqaGI444ggsuuIDMzMxdjrF27VqmTJnCf/7zHy666CLefPNNLr/88lY9D6VUy1X5AnywbAsfLtvC6q0VbC7zEhsdxSlDuzGmXwaPzMyjrNrPNcf0I6dLIrHRUcz7cTsfLd/K6wsDDOmewq9PGcTabZU8/816AnWG4wZl8+hlo0iOi+aGEwYwb912xg7IJDnuwIzwj+Sn9ALyQ5YLgCMbbfMdcAE2fXQekCIimcaYktCNRGQyMBmgd+/eEStwaxkzZswuY/0feugh3n77bQDy8/NZu3btboGgX79+jBgxAoDDDz+c9evXH7DyKqUaBOsM89dv59OVhcRGRzGydxdyMxJYvLGUb34o4bNVhVTXBumTmciYfhkM7JbCtnIv7y3dwgfLtjCoWzLPXzWGYT1Tdx7z0jG98QWCFFfW0iu9oaW/9fShzFu/nYmHdN+ZOkqNjzkgrYBQkQwETY11bPwUnN8Aj4jIlcAs7EO7A7vtZMxTwFMAo0eP3uOTdPZ05X6gJCUl7Xz9xRdf8Omnn/Ltt9+SmJjI8ccf3+S9AHFxDbk/j8dDTU3NASmrUm7mD9YhQLRn93Evc9eV8MCna0lLiKFvVhJRAmu3VVKwo4ZjBmZxxbg+ZCXHMX3ZFt5YWEBptR+AwnIvJVW1xEZHUVdnCNQ1VDlZyXGceVgPLhqdy+F9uuwypPtPZw5j5eZyBndPIT5m977BuGjPLkEAoHtaPGcP79lK38b+i2QgKAByQ5ZzgM2hGxhjNgPnA4hIMnCBMaYsgmWKiJSUFCoqmn7iX1lZGV26dCExMZHvv/+eOXPmHODSKeUupdW15G2r5OCeaSTEenZZnxQXTYwnCmMMU+fn848PVhHtEU4Z1o3TDu7OyN5d6JIYw/PfrOfvH6wiOyWOhFgPn31fiDHQLyuJrOQ4nvn6R57+ah0p8TGU1fjpl5XEgOxkAIZ0T+Gkod04fnA2nihh+aYyNpRUMzw3jQHZyc3ezxPjiWJ4bvoB+Y5aWyQDwXxgoIj0w17pXwJMCt1ARLKA7caYOuAO7Agi18nMzOSoo47ikEMOISEhgW7dGpp1EyZM4IknnuCwww5j8ODBjB07tg1LqlRkGWOarSjLvX62V9bSNytpt/dWb61gyryNzFpbxLoiO4QyPTGGS8f0ZkB2Mm8tKuCbH0pIiYtm7IBMymv8zP1xO2P7Z9AtNZ7py7by2gI74DArOY7iSh8nD+3KfRePIDU+hkCwDgM70y+bS2t4cc4GtpTWcOHhuYwfkElUVNPlHt03g9F9M1rh22m/IvrMYhE5HXgAO3z0WWPM3SJyF7DAGDNNRC7EjhQy2NTQL40xvj0dc/To0abxg2lWrVrF0KFDI3IO7U1nOlfV/gXrDCs2lzE7r4Sv84pYuGEH4/pn8pvTBjOsRyqL80t5e9Em5qwrIa+oEmNg/IBMfn3KILJT4pixspAPlm1h8cZSYj1RHDMwi1F9utAnM5H3vtvMjJWF1BnIzUjg3BG9KK6s5au1RVR4A/x+whAuHZOLiOALBFm4YQfLN5WxfFM5h/RK5RdH92+2cu+MRGShMWZ0k++57eH1Ggg6z7mq1re1zMtTs9YxqFsy547s1WQu2+sPEiVCjEd2uboP1hneWJjPgvU78AbqKKvxs3jjDiq8tltvSPcUhuek89GKrZTV+OmVnsCm0hriY6IY2z+TUb27EO0Rnv36R4ora3ced0j3FC48PIfzR+WQkRS7S1nyt1dTXOljeE76zkq9vs7SKVf2zZ4CQYeYfVQptXcfLtvCHW8vo6zGjzFw7yerOXt4L9ITY4iNjmJNYQUL1u9g4/bqnfvUV9IH90zjno++57v8UrKS40iJjyYx1sOZh/VgbP9MxvXPpGtqPAB/OGMoT3+1jmWbyvjViQdxxmE9SIlvmDr9yvF9eX1BAcE6w8lDu9E7M7HZMudmJJKbsev7GgBanwYCpdoBYwxrt1VSZwxDujcMO9xUWsOiDTvISIolKzmOjKRY0hJiqDOG1VsrWL65jOKKWryBIFW+AJt21FCwo4ZeXRK48cSDGNW7C2sKK7h/xho+XL6Vw3LSeODiEbZl8NU6XpyzHn/QXmFnJsUyum8XfnJ4DiLgC9Qxa20xf/9gFQBZybE8cPEIzhnRc4+VcVpCDLedOrjZ9xNjo/nZ+L6t88WpVqGBQKkwBIJ1fLpqGy/P3cCO6lpOHNyVk4Z2IzcjkeS4aGKjm5+2yxjD4vxSXvx2A7PzihnWM5Vx/TPpnhZPabWfzaU1zFhZyLpi20l6wuBsfnFMf2asLOTluRt2VtShRCA0qxvjERJjo+mZnkBuRgKLNpZy/mPfMKxHKqu2lpMY4+HWkwdxwwkDiPFE0T87mfEHZe08N2+gjqRYz24V/G2nDmZNYQWLN+5gwsE9SEvUhyJ1RBoIVKfW1CgXYwxby70s31TOys3lfL+1nIUbdrCtwkfPtHh6dUngkZl5PPR53s59eqTFc/VR/bj0yN5sLfPy0pwNfLW2iNpgHV5/HUUVPpLjojluUDbfby3ni9VFO/f1RAlj+2dw1dH9qPD6eWrWOi57ei6eKOGi0TlMGtOHqtoAxZU+dlTVUlrtxx+sY0iPVA7tlUbP9AQ8jTpFq3wBnv92Pe8u3sy1xw5g8rH9d8u/14v2RJHcxDj8eoO6pTCoW8p+fLvKLbSz2GU607nur+Wbyiiv8e+84gU7dHHN1gq6psSTnhTD56u28cq8jSzZWEr3tHhyutgbfXZU+9nm3FAE9sq7b2YSw3qkcs6Inpw4pCvRnii2V9UyO6+Ykkoflb4As/NK+HZdCYmxHqprg8R6ojh2UBap8TF4ooThuemcN7IXSc6UAdvKvZR7/aQn2lRP6IRkFV4/M1YWMiI3nf7O2HalWko7iyOstLSUV155ZbfZR8PxwAMPMHnyZBITm+8wcyNfIMi2ch890uKbvOtzb6prA6wrqmJDSTVVvgAjeqdzUHYyW8q9fLB0M1+tLWZzaQ2F5T6G56bx7wuH0zM9gY+Wb+GmqUuoDdTx86P7cfvEIczOK+Z3byxlW8WuI5P7ZCZy2djelFTWUrCjGhGhV3o8h/VKY2iPFA7NSWNoj9Sdk4mFykiK5ayQO0JvPHEgizfuYMq8jfTJTOLiI3L3OFNk19T4nZ2rjaXEx3D+qJx9/s6U2l/aImgF69ev58wzz2T58uX7vG/9DKRZWVl735i2P9c98fqDPPjZWmatKWJNYQX+oCHWE0X/7CQOy0nj6IHZjOufSVZyLCKC1x9k1ZZy1hZWkpYYQ26XRIoqfby+IJ9PVhRSG6zb5fgpcdFU+BqGKvbPTqJLYizvLN5EtCeK80b24oVv1zM8N51Deqbx4pwN5GYkkL+9hkHdkrnl5EFU+gIUVfgYkZvOuP7N30SkVEejLYIIC52G+pRTTqFr16689tpr+Hw+zjvvPP72t79RVVXFRRddREFBAcFgkD//+c8UFhayefNmTjjhBLKyspg5c2Zbnwpgx4s3zjmDzZ1vKKmmqjbA4G4pu1zp52+v5vqXF7J8UznjB2Ty86P7k5uRwMbt1awtrOSj5Q13fkYJJMVFU10bJFi3+4VIemIMk47szZh+GfTNTCIuJopFG3awOL+UnmnxnDW8J30yG+5OveaY/tw0dTHPfbOeE4d05dFJo0iI9TCmXwZ3vb+Sa47px22nDm5yzLxSqiMGgg9vh63LWveY3Q+Fifc0+3boNNSffPIJb7zxBvPmzcMYw9lnn82sWbMoKiqiZ8+efPDBB4CdgygtLY377ruPmTNnht0i2Ffri6tIS4ihS6OOQq8/yPqSKnZU+RnQNYmuKfEsLSjl4c/z+HSVzU9PPKQ73dMSWL3VdpouyS9lhzMxV1Ksh5G9u5CeGIMBZucVE6wzzc6fHqwzLC0oZeGGHZTX+Cn3BkiOi+aQXmkM6Z5CuddPwY4aoqOE4wZnExe9a6U9IDuZn4zO3e24AH2zknjjuvHMWVfCuAGZO/PtZw3vuUv6RinVtI4XCNrYJ598wieffMLIkSMBqKysZO3atRxzzDH85je/4fe//z1nnnkmxxxzTKt+bnGlj8dm/sD4AZmcOKQrVbUB7v5gFVPn25nAB3ZNpm9WEkUVPraU2dx6qPTEGEqr/aTGRzNpTG++KyjlH9O/ByA6ShiQnczJQ7sxsncXEmM9LNywg8X5O9hcZmdJPbhnKnefe2iT88iAHRkzsncXRvbu0uw5HJaz/xN2xUZHceyg7P3eX6nOrOMFgj1cuR8IxhjuuOMOrr322t3eW7hwIdOnT+eOO+7g1FNP5c4772yVzyzYUc0Vz8xjXXEVz87+kb6ZidQG6tha7uWaY/qRnhjL/PXbWV9cRfe0eA7qmk3vjET6ZiXRJTGGtYWVrN5aQd+sJC4f23vnXaD526up8AYY0DVptyv0c0f2apWyK6XaXscLBG0gdBrq0047jT//+c9cdtllJCcns2nTJmJiYggEAmRkZHD55ZeTnJzMc889t8u+4aaGAsE67v5gJV+tLWZgtxSG56TxzNc/UuULMHXyWIoqfDz/zXr8wToevWzUHq/A6x0zsOkr6ca39iulOiYNBK0gdBrqiRMnMmnSJMaNGwdAcnIyL730Enl5efz2t78lKiqKmJgYHn/8cQAmT57MxIkT6dGjxx47iwPBOjaV1rC13Md/Z2/liL4ZzPuxhPe+20x2ShyvXjuOoT3s1ASaF1dK7QsdPuoClb4A+durCdQZqgs30PegQXRLjccYw6bSGtITYw/Ys02VUu6kw0ddqNzrp9IboKY2SHVtgNhoDwdlJ7K+PIZuzo1IIkJOF03fKKVaRgNBO7S9yt7pGiVCQoyHrJQ4uqbENzm2XymlWqrDBII9PSLPTSq8fjbtqCE5Ltp54HbDObV6Gi/gg7ICyBzQusdVSrnKvk8C0w7Fx8dTUlLS+hXlgWQMvtIt+Es2EB8TRZ/MxN2CQElJCfHxTc9Ps4ttq2DLdw3LdXXwzcPw8k9g4xy7rmgNPH0SPHw4bFrUyiejlHKTDtEiyMnJoaCggKKior1v3A6ZYIBgVQnRdfYmr7qkStZs333CsvhgJTnZqbuttwcxMP9pWPg8FDp3Vg88DcbfCF/dB+tmQkwSrP0E+h8P+fMgJgHiU+GLe+Cy1yJzcpFQWw0/fAZDzrTTgyqlWqRDBIKYmBj69evX1sXYL9vXzCbq1UuINT6+yLmOiVseQ468Fk67u2GjjXNgxp2QPxdiU+DSV6Dfsbse6McvYfpvoMdwmPi/4K+Gr+6HtR9DdAKc9SAc+hOY8xh8/SDkHAHnPQlLXobP/wc2LYReh9tjGbP3CtZXCcvfhIx+0OdoiIpqel9j4LUrIGsgnNQ6N9Ax+0H48h4493EYMWnP24ZzLkp1ch1i+KhbBVd/gn/q5RTWpbP9nJcYOWoMvHIJbF0Ktyy3levil+DdX0Jydzj6Vlj4X9i+Ds7/Dxx8bsPBPvkTzHkCfr8e4pw57Ku3w+IXYdAEyA55dGCgFjwxtoL0lsODh9nAcMkU+PJf8M1DkNIDuh8CA06CkZfb7QGCflj0gm1FVG2z61J7Qe6RULIWilbDuF/CyX+17/3wObx4HsSlwm/zILr5qZmb/6L8DZ8fqIX7D7afnZgJNy6AxIym91v9EUy7Ec5+BAZP2PfPVaoD2dPw0Q7RR+BKK6chUy4hL9iD70591QYBgEMugPJNkD8HfBXw6V8hdyzctAjGXgdXfQg9R8LrV8LWkGmvf5gJvcc2BAGwFeRRN+8aBACiYxuukuNTYfyvbMroqeNg1v/CQSdDj8Ps8d+/BR4dYyv/D2+H+4bCB7+GzIPgyulwwTPQ7WCbakrqCr1Gw+yHYMtSezX+xT3giQNfOeR92vR3UZwHS1+zrZ5vH931vTmPw/8NtsEPYOW7NgicchfUlNrvpymLX4Kpk6CqCL74x67PdawXqIWq4l3XbfkOPvy97Wept3kxfPQHqGxnqceaHfDl/0LeZ21dEuVyHSI15EaVH/+dgrqeTBn2OHcfNbLhjcETbSpn+Zv2arqqCC59FWKdydwSM+DSqXDvIJvWmfBPqNgKhcsbrsL31ZjJtgIu3Wgr9kMvtOuNgTUf28p22q/AEwuDToNRP7PBoj6Y1G8PtnJ65AgbLI673aazJv6vbWksewOGnNGwbcAHM/4Ccx93VghgoM9R0HME+Gtg1r1QXQJvXw9XTYd5T0LGABj3K6jcBt8+Ar3HQVove7yi1TbNteItGHAiDDwVPrrdps76H28/Zst3NrAtf8uWd/glcMIfYNX78OlfIFgL856yaSe/F5a/YfcryYNJr+5fqqmyyB5n82IbxFK67/sxdn5vtfZ7mHUveEshKRtuWgxx+jhJtX80ELSBj2fN5rSy1XyR+Av+dP6Ru74Zl2zTGMvftJXQIRdAzuG7bpOYYbdZ+pqtVH743K4fcNL+FSguBX7xme08Dq2gROznDDzFXvF3HQIJe5m7KKELnPp3ePtaePNqSM2Bw6+0FfR3U6C2yga14rXw+lW2Y3vMtTD6KkjuBg+NtK2ISVNhyStQXQyjr4YFz9pjFsyHCf+yabPj77AthHeu27UMyd3hiGvgtH8ABr6+3/Yr9D8evv8AXv2pTTUNPt1+5oJn4bupdtvBp8Mp/2PXzf8PiAeO+Y39bj7/H1j0vD2fpgQDNgAOnmj/AdQFYdpN9txNECQKClfAlR9AQshsq95y2LYSEjIge1DD+kUv2NbeqX+3wc5bDq9eBj/OssH4kAvt+c9+EE78Uzi/ttpXRWvgs7/B2Q83n4Z0OQ0EB5AxhvtnrMH/5QucFgOTrryRhNgmHpZyyAWw4m17Bd5cB+vwSbDqPZsWyPvMXhV2O2T/C5exh872KA/0GRf+sQ67GBa9CBu+tq2U6Dh7TguegdVOauu/E8HU2dZOaP5+3I0w8+9QsMAOee11OJxxn03hLHvdjnwacandNi4Zrp1lK1CAqGibskpqNIHfkdfZ/5HnPGHTTz1HwOVvNgS1cb+E2Q/YFNfhV9kAOOEftk8mymP/56+rs5XvR3+Afsc1/X0tf9MGiqWvwS8+tX0sX/wTlrxkA9MRP4eKLfDyRTDlEhuoVr4DK6fBjh/tMcQDx98OR/8aZv3bdoqDDfan3Q1zn7Bpq/OetC0ZsCm3bx6xATM63raAjIGJ/4pcxVVXB2s+tK2x1vqMWf+26b7QgRKtrXyL7XM74Y+7X2A1Z85j8P37kN7btsA7IO0sPoDmr9/OT574lq/S76JXRiJRk5uZZM7vhQeH29TEyX9peptALdw3xKZRNsy2V4fnPxW5wu+r0o2w9FUYf7Ptk6irs528XfpCeYFtGVz10a5Xv2CveB841F6BV2yBi16AYedAVQn85wQbUJr7TppTU2o/u7YSsgbbfpakzH0/p7ICeGw8BLy2wo2OhdPvtZ32wYDtS4mKBm8ZxMTDcb+Hd66HUVfYq8l6y9+CN64GjN1+wIm2f6frwTaYLHsN0nKhLB9GXA5H3QRvTYYtSyAmES56EQae3HC8HRvgkdH2b6F4jU2ZASR3hXMfg/h02wqJTYKhZ9ngtjd1dbblUb0dDvsJHHx+Q4VvDEz/rW0xxafZoHXktfY3218b58Kzp9rXjS8OWosx8NIFduhx7li4+qO9p/n8Xvi/QXbIMsCN8yCjf+uX7QDYU2exBoID6L4Za3jr82/4Ou5me6V89K3Nbxzw2RbBnv5Qp//O5ooBznsKhl/cmsVtfR//0eb0Y5PhZ+9Br1FNbzfr3/D53+3/cDcuaKi4gn5bce5Pjn7WvfZK/advQVoLHgyfP89W5GBbPMV59uq/cLlNXV38kk03/fd0qPNDz1E28MQ0uhFw1Xu2b+fg83ZvwXw31V7Vj74aTvyzPd9Arb1PpM9426JprP67zegPFz5r173xc9j+w67bdT0YTvqzTQduXW4HCwy/dPfvdOFz8N7NkNYbyjbav8UjroFjfwNzn7QtlcOvtFfYaz+G9D62fyn3iF2PEwzAoufs99Dc7x0M2IEKNTtsufzVcMNciE2E9bNtcBt1xZ4DmDF2f+M85zqhy+7bz38aPrit4eLpp+/AgBOaPybAinfg9Z/BuU/YtN/AU+Gi5/e8T2vwVdrA3YpDnzUQtBMXPfktp5a9wS+qn4ZfLWr51A6bF8NTx9vXv1lrrwDbs6LV9kr4tH9A/+Oa385XAc9OhKNv2bUjuqVa+56CikJ48lhbyUuUTVtdO8v2Xyx60VaYk6buX+DZ17LWVtnWxMHnNXQa+yph6VRIzLJpr61L4bO7YMf6Xfed+G84cnLDclWxveO82yFw5fv20a9zn4TvXrEDGfxVdnoSQjAAAB0KSURBVEjx2Y/YMv44y6ZbyjbZTvexN9hKvHQjvHmNHQEXnQA/ec5e6fsqbR8MxvZxrHgbPvmjbekkZsJzp9uRbFHR8PUDdru+x9gWb2qjKda/ecT2+xSuAF9Zw/r0PjatevD59vfY9r1tUfYea4dJPzzK/i5Xf9zwPdcPjti8GI65zbb4XrnEtsRuXWFHaH15D/x8BuSOCfnuq20Z6wd07K8lU+zvVbjCDhJJyLC/W7/jbIsrvpmbScOkgaAd8PqDHPbXT/isy93kJhm4fnbLD2oMPD7eXq1d+2XLj6f2Xf68hqv/i1+GoWe2dYn2LFALq6fb/pWuB8P7t0LeDPjZ+w39QG9fb/tjrp+969DjwpUw826bDjrrIfCEdDF6y+C9W+xoLYmyI7sqt9kr9FPvsp3eW5bafpIV7zTcg4I46bETYNJrtlJ++3obdMCOUOs1yvbNRMfaFlffo+17y9+0FxbdD4Oc0ZA50A4CCPrtiLrC5bbPqLYaKjbbct8wxwaT+tbBT9+2/RwF82HmP2HjN/bYh1xoL1juH2b7kE65ywawh0fZ9OWQ0206dt0XdrSZCIy/yW4bOoS7OaX5tjz1lfuiF+zIvKxBkDPG9kGVbrRBePMiG8yP+53tw4qO3fOxm6GBoB2YnVfM7c9M46u4W21H1XG/a50Dl260/03v3TrHU/tu2Ruw/ms483733cXsLYOnTrD9J+N+adNFy16zef997YsxxnZq58+zlTDAqf9j01W+Cjtaa91M6D3eVqyJGTbgbJxj73zv0sfuU1VsR1od9hPbwgGbgps6Cco3w5Xv2fTbY+NsRX/1x7sGJbCjtZa9bu8nSe1pr6wHTWzokwr44KFRNp0UqLEBKynb9ut4S21qMnOgvUnyhjnQ1XneSdEam45d/qaTykqzfUQ12226LzGr6ZZ+Wq4tQ3Sc/XvZvMj23Rxzmy3fW9dA/xPs0PDGFf2mhXaY9fqv9p5S3gMNBO3A/R8u5eRvr+CQhGLk+m+04lbtR+FKeOZUqK2wd5T3GW/TPrGt/KyLoB+Kvrcpp/0JmOWb4ZnTbGoqaxBsXgLXfQ1ZB+1feVZ/ZFsOXYfaSnrAiTatZoy9U//bR6DHiKZb24FaG+y6Dmvo/8mfZ/fxlu26bV3QpuPK8u1y90NtymrD7IabLHOOgCvebT69ZIzdNneMbUnsBw0Ebc0YPvvXTzjJO8PmJ4ec3tYlUmpX3jJbUTfuuG5vSn6wQau62I7YGnNNZD6nrs5W6rljbL9Ca6gptd9zfcsHYN2Xto/j+Nsjfo+CBoI25pv7LHEf3srsnldx1OQH2ro4SrnbtlW2Aj3yWvel4tqQPqqyLdWU4vn0Tr4OHkzw2NvbujRKuV/XoQ05e9UqdNK5SJv7BNH+Cv5Vdzmj+7XzZrdSqlPSFkEk1ZTCt48xN2480V2HkxSnX7dSqv3RmimS5jwOvjLuk3MZ2qNlN4MopVSkRDQ1JCITRGS1iOSJyG4JchHpLSIzRWSxiCwVkY4znKZmB8x5jNqBZzC3JocB2WHcZKKUUm0gYoFARDzAo8BEYBhwqYgMa7TZn4DXjDEjgUuAxyJVngPuh8/BV84PA68CoH92C28/V0qpCIlki2AMkGeMWWeMqQWmAuc02sYA9TmTNGBzBMtzYDlPs1pVa+f/OUhbBEqpdiqSfQS9gPyQ5QKg0VNY+CvwiYj8CkgCTqajqC4GiWJVqYe46Ch6prdgil6llIqgSLYImrrTo/Hda5cCzxljcoDTgRdFZLcyichkEVkgIguKitrZc2ObU1UEiZn8UFxDv6wkPFF644tSqn2KZCAoAHJDlnPYPfXzc+A1AGPMt0A8sNtge2PMU8aY0caY0dnZ2REqbiurKoakbNYVVTKgq6aFlFLtVyQDwXxgoIj0E5FYbGfwtEbbbAROAhCRodhA4JJL/r2oKqIuMYuN26t1xJBSql2LWCAwxgSAG4GPgVXY0UErROQuETnb2ew24BoR+Q6YAlxp3Db5UXOqiqmMTqfOwAAdMaSUasciekOZMWY6ML3RujtDXq8EjopkGdpMVTHbu9gBUdoiUEq1ZzrXUCQEfOArY2vABoB+WdoiUEq1XxoIIqGqGICNviR6psXrHENKqXZNA0EkVNtA8ENVvI4YUkq1exoIIqHKDnxaWR6n/QNKqXZPA0EkOKmh/NokHTGklGr3NBBEghMISkyatgiUUu2eBoJIqCqiTqKpIIFeXXSOIaVU+6aBIBKqiqmOzQCEjKTYti6NUkrtkQaCSKgqotKTTmx0FMk6dFQp1c5pIIiE6mLKotLJTIpFRGcdVUq1bxoIIqGqiO0mVdNCSilX0EAQCVXFFNalaCBQSrmCJrBbW20V+KvZQjKZGgiUUi6gLYLW5txDUOBLIiMpro0Lo5RSe6eBoLU5gWBLIJnMZG0RKKXaPw0Erc2ZZ6jEpGpqSCnlChoIWpsz82gJadpZrJRyBQ0ErW1niyBFU0NKKVfQQNDaqooJeBKoIV47i5VSrqCBoLVVFVET0wVAU0NKKVfQQNDaqoqp8HQhxiOkxuttGkqp9k8DQWurKqI0ynYU6zxDSik30EDQ2qqKKDGp2j+glHKNsAKBiLwpImeIiAaOPQn6oWIrm+sy9B4CpZRrhFuxPw5MAtaKyD0iMiSCZXKvykLAsDGQrh3FSinXCCsQGGM+NcZcBowC1gMzROQbEblKRGIiWUBXKdsEwDqf3kymlHKPsFM9IpIJXAn8AlgMPIgNDDMiUjI3KreB4IfadE0NKaVcI6zxjSLyFjAEeBE4yxizxXnrVRFZEKnCuU75ZgC2mgwyk7WzWCnlDuEOdH/EGPN5U28YY0a3YnncrXwTwehEyknU1JBSyjXCTQ0NFZH0+gUR6SIiN0SoTO5VvglfYndAdJ4hpZRrhBsIrjHGlNYvGGN2ANdEpkguVr6ZyrhugE4voZRyj3ADQZSE3CYrIh5Aa7rGyjZRGp0NoJ3FSinXCLeP4GPgNRF5AjDAdcBHESuVGwUDULmV4tRMPFFCaryOqlVKuUO4geD3wLXA9YAAnwBPR6pQrlRZCKaOrSaTjKRYoqJ0niGllDuEFQiMMXXYu4sfj2xxXMy5hyBfp5dQSrlMuPcRDAT+CQwD4uvXG2P6R6hc7uMEgg21Or2EUspdwu0s/i+2NRAATgBewN5cpuo5N5Pl+VI1ECilXCXcQJBgjPkMEGPMBmPMX4ETI1csFyrfDNEJbKqJIz1RO4qVUu4RbiDwOlNQrxWRG0XkPKDr3nYSkQkislpE8kTk9ibev19Eljj/1ohIaVPHcYWyAkjrRUVtkOQ4DQRKKfcId9TQLUAicBPwP9j00M/2tINzr8GjwClAATBfRKYZY1bWb2OMuTVk+18BI/ep9O1J+WbqUnpSu6mO5DhPW5dGKaXCttcWgVOhX2SMqTTGFBhjrjLGXGCMmbOXXccAecaYdcaYWmAqcM4etr8UmBJ2ydub8s34k7oDkBynzypWSrnHXgOBMSYIHB56Z3GYegH5IcsFzrrdiEgfoB/Q5MR2IjJZRBaIyIKioqJ9LMYBUBeEii14E3oAkKw3kymlXCTcS9fFwLsi8jpQVb/SGPPWHvZpKnCYZra9BHjDCTq772TMU8BTAKNHj27uGG2nshBMkKp4222iLQKllJuEW2NlACXsOlLIAHsKBAVAbshyDrC5mW0vAX4ZZlnaH2foaEWsDQQp8RoIlFLuEe6dxVftx7HnAwNFpB+wCVvZT2q8kYgMBroA3+7HZ7QPZQX2PzHZQLW2CJRSrhLuncX/pYm0jjHm6ub2McYERORG7IR1HuBZY8wKEbkLWGCMmeZseikw1RjT/lI+4arYCkBJVBawkWRtESilXCTcGuv9kNfxwHk0n+bZyRgzHZjeaN2djZb/GmYZ2i+/7TYpDdrHU2qLQCnlJuGmht4MXRaRKcCnESmRGwV8AJTX2kFYGgiUUm4S7p3FjQ0EerdmQVzNXwOeOCprg4hAYqzeUKaUco9w+wgq2LWPYCv2GQUKbIsgJp4Kb4DkuGj2/ZYLpZRqO+GmhlIiXRBXC3ghOp5KX4AUTQsppVwmrNSQiJwnImkhy+kicm7kiuUyAS9Ex1HpDeiIIaWU64TbR/AXY0xZ/YIxphT4S2SK5EIBL0QnUFUb0I5ipZTrhBsImtpOa7x6AR9Ex1HhDZCkgUAp5TLhBoIFInKfiAwQkf4icj+wMJIFcxV/DcQk2D4CTQ0ppVwm3EDwK6AWeBV4DajBzXMDtTanRVDp1dSQUsp9wh01VAXs9oQx5Qh4IT6VSl9An06mlHKdcEcNzRCR9JDlLiLyceSK5TIBL8YZPqqjhpRSbhNuaijLGSkEgDFmB2E8s7jTCHgJRMUC6H0ESinXCTcQ1InIziklRKQvzT9kpvMJ+PCLDQTaIlBKuU24tdYfga9F5Etn+VhgcmSK5EL+GmrrA4G2CJRSLhNuZ/FHIjIaW/kvAd7FjhxSAAEfPqOBQCnlTuFOOvcL4Gbs4yaXAGOxTxQ7cU/7dQrGQKAGH5oaUkq5U7h9BDcDRwAbjDEnACOBooiVyk2CtQDUGBsAtEWglHKbcAOB1xjjBRCROGPM98DgyBXLRQJeAGqMvX9AA4FSym3CrbUKnPsI3gFmiMgOwnhUZafgt4Ggus4GAp1iQinlNuF2Fp/nvPyriMwE0oCPIlYqN3FaBFVB+1XqpHNKKbfZ51rLGPPl3rfqRJznFVfVRRMfE0WMZ3+f/qmUUm1Da62WCthRtBWBaO0fUEq5kgaClnJaBJVBjwYCpZQraSBoKaePoNzv0XsIlFKupIGgpZxRQ2V+TQ0ppdxJA0FLOS2CUn+UPotAKeVKGghayukjKPVH6T0ESilX0kDQUs6ooR2+KE0NKaVcSQNBSzktgu21UXozmVLKlTQQtJTftggqgzGaGlJKuZIGgpZyWgQ+YjQ1pJRyJQ0ELRXwYiSKAHpDmVLKnTQQtFTAS50nHhC9oUwp5UoaCFoq4KXOEwdAirYIlFIupIGgpQJeglE2EGiLQCnlRhoIWsrvJRBln1esw0eVUm6kgaClAl78YgOBpoaUUm4U0UAgIhNEZLWI5InI7c1sc5GIrBSRFSLySiTLExEBH7WiqSGllHtFrOYSEQ/wKHAKUADMF5FpxpiVIdsMBO4AjjLG7BCRrpEqT8QEvNQSQ4xHSIjxtHVplFJqn0WyRTAGyDPGrDPG1AJTgXMabXMN8KgxZgeAMWZbBMsTGQEvXhNDanwMItLWpVFKqX0WyUDQC8gPWS5w1oUaBAwSkdkiMkdEJjR1IBGZLCILRGRBUVFRhIq7nwJeaoglNUGnoFZKuVMkA0FTl8em0XI0MBA4HrgUeFpE0nfbyZinjDGjjTGjs7OzW72gLeL3UlMXTar2DyilXCqSgaAAyA1ZzgE2N7HNu8YYvzHmR2A1NjC4R8BHVV2MtgiUUq4VyUAwHxgoIv1EJBa4BJjWaJt3gBMARCQLmypaF8Eytb5ADVVBD6nxGgiUUu4UsUBgjAkANwIfA6uA14wxK0TkLhE529nsY6BERFYCM4HfGmNKIlWmiAj4qAxGk5qgqSGllDtFtPYyxkwHpjdad2fIawP82vnnTgEv5YFobREopVxL7yxuibogBGupDkZrH4FSyrU0ELREyENpdNSQUsqtNBC0RMALgJdYUjQ1pJRyKQ0ELeEEAh8x2lmslHItDQQtUR8InCkmlFLKjTQQtITTR+DVKSaUUi6mgaAl/DVAfWexBgKllDtpIGiJXVoE2keglHInDQQt4fQRBCRWn0WglHItDQQt4QSC6LgEfRaBUsq1NBC0hBMIYuIS27ggSim1/zQQtITfBoLYeA0ESin30kDQEk6LIE4DgVLKxTQQtIQzaiguQQOBUsq9NBC0RMDeR5CQkNTGBVFKqf2ngaAlnBZBQqIGAqWUe+ldUC0QqK0haKJJTYht66IopdR+00DQAn5vNX70wfVKKXfT1FAL+H3V+IjVeYaUUq6mgaAFArVefRaBUsr1NBC0QMBXrc8iUEq5ngaCFqjze/VZBEop19NA0ALG79VnESilXE8DQQsYfw1eo88iUEq5mwaCFpCAj1p9FoFSyuU0ELSABL3URcXqswiUUq6mgaAFooI+gp74ti6GUkq1iAaCFvDU1UJ0XFsXQymlWkQDQQvE1PkgWlsESil300DQAjGmFmI0ECil3E0Dwf4yhlhqiYpJaOuSKKVUi2gg2F/lm/BQR21it7YuiVJKtYgGgv20cc1iAKK6DmnjkiilVMtoINhPa5YtAGD06LFtXBKllGoZDQT7oa7OUFGwgoqoVDK79mrr4iilVItoINgPc34soVdgI7VdBoLeVayUcjkNBGHI317NRU98y7tLNgHw9sICBskm0nIPaeOSKaVUy0V02kwRmQA8CHiAp40x9zR6/0rg38AmZ9UjxpinI1mmfVVW7eeq5+aTt62Seeu3s6XMy9wVa0iXSug+tK2Lp5RSLRaxQCAiHuBR4BSgAJgvItOMMSsbbfqqMebGSJWjSUumQNYgPi3P4YNlW/jLWcNI3zgDouPZlDWeP7y1jBG56Uw8tDt3vbeSjSUVzBi/kidKRnLPh98zNmoDxAJZgw5osZVSKhIi2SIYA+QZY9YBiMhU4BygcSA4sGY/CDPuxCsJPOT9A0vNAI6o+JxJBX/DREXzWtZfmV0wgFlri3jws7UA/PdkYeDXd/Pvcb8iocvF9PlhNlQA2Tp0VCnlfpEMBL2A/JDlAuDIJra7QESOBdYAtxpj8pvYpnUsehFm3MmXniPpH/iRV5Pu5cueP+ekDQ9S1v1IjK+S6wrv4qBxTzLmuNOZvmwLqfExnFA5BYCole/w95vvgo/8sCQFUntGrKhKKXWgRLKzuKnhNKbR8ntAX2PMYcCnwPNNHkhksogsEJEFRUVF+1eaVe/DezexIX0sv6j6JdvOnUJCXBwTNt7Hj1F9mFR5CxdV3kaJJ5szV9xCt2AhVx3VjwsOz4EfvwTxQFk+FMyHou8he5COGFJKdQiRDAQFQG7Icg6wOXQDY0yJMcbnLP4HOLypAxljnjLGjDbGjM7Ozt6/0kTH48s5inNLruPUQ3M5fORo+OnbMOoKtp/3CitKDHlV8VReOBXxVcCiF+x+tdWQPxdGXWFnGl3+BhSt0bSQUqrDiGRqaD4wUET6YUcFXQJMCt1ARHoYY7Y4i2cDqyJWmoEn87sFGVSZQm6f6FTi3Q+Bsx9mLPDbkhiS46IZMqwvDDgRlr4KJ/wRNn4LwVoYciZUl8DS18Bbqh3FSqkOI2KBwBgTEJEbgY+xw0efNcasEJG7gAXGmGnATSJyNhAAtgNXRqo8Czfs4N3vtnDjCQeRm5G42/u/POGghoXhl8KbP4cNs21aKCoG+owDfxWsmma30RaBUqqDiOh9BMaY6cD0RuvuDHl9B3BHJMtQb/XWCnIzErj++AF733jIGRCXCt9NgcLlkDsGYpNg4KkQmwK1FbaPQCmlOoBOc2fxpCN78+mvjyMpLozYF5MAw86BFW/DlqXQ77iG9UPPssEgvU9kC6yUUgdIpwkEAHHRnvA3Hn4p+KsBA/2Pa1g/4R9w9UcQtQ/HUkqpdiyiqSFX6z3OXvVXl0CvkMFMCV3sP6WU6iA0EDQnKgpO/zdUFoInpq1Lo5RSEaOBYE8GndbWJVBKqYjrVH0ESimldqeBQCmlOjkNBEop1clpIFBKqU5OA4FSSnVyGgiUUqqT00CglFKdnAYCpZTq5MSYxg8Na99EpAjYsJ+7ZwHFrVicttSRzgU61vnoubRPnf1c+hhjmnyyl+sCQUuIyAJjzOi2Lkdr6EjnAh3rfPRc2ic9l+ZpakgppTo5DQRKKdXJdbZA8FRbF6AVdaRzgY51Pnou7ZOeSzM6VR+BUkqp3XW2FoFSSqlGNBAopVQn12kCgYhMEJHVIpInIre3dXn2hYjkishMEVklIitE5GZnfYaIzBCRtc5/XfMMTRHxiMhiEXnfWe4nInOdc3lVRGLbuozhEJF0EXlDRL53fp9xbv1dRORW5+9ruYhMEZF4N/0uIvKsiGwTkeUh65r8LcR6yKkPlorIqLYr+e6aOZd/O39nS0XkbRFJD3nvDudcVovIPj9Rq1MEAhHxAI8CE4FhwKUiMqxtS7VPAsBtxpihwFjgl075bwc+M8YMBD5zlt3iZmBVyPK/gPudc9kB/LxNSrXvHgQ+MsYMAYZjz8l1v4uI9AJuAkYbYw4BPMAluOt3eQ6Y0Ghdc7/FRGCg828y8PgBKmO4nmP3c5kBHGKMOQxYA9wB4NQFlwAHO/s85tR5YesUgQAYA+QZY9YZY2qBqcA5bVymsBljthhjFjmvK7CVTS/sOTzvbPY8cG7blHDfiEgOcAbwtLMswInAG84mrjgXEUkFjgWeATDG1BpjSnHp74J9dG2CiEQDicAWXPS7GGNmAdsbrW7utzgHeMFYc4B0EelxYEq6d02dizHmE2NMwFmcA+Q4r88BphpjfMaYH4E8bJ0Xts4SCHoB+SHLBc461xGRvsBIYC7QzRizBWywALq2Xcn2yQPA74A6ZzkTKA35I3fL79MfKAL+66S5nhaRJFz4uxhjNgH3AhuxAaAMWIg7f5dQzf0Wbq8TrgY+dF63+Fw6SyCQJta5btysiCQDbwK3GGPK27o8+0NEzgS2GWMWhq5uYlM3/D7RwCjgcWPMSKAKF6SBmuLkzs8B+gE9gSRs+qQxN/wu4XDr3xwi8kdsuvjl+lVNbLZP59JZAkEBkBuynANsbqOy7BcRicEGgZeNMW85qwvrm7POf7e1Vfn2wVHA2SKyHpuiOxHbQkh3UhLgnt+nACgwxsx1lt/ABgY3/i4nAz8aY4qMMX7gLWA87vxdQjX3W7iyThCRnwFnApeZhpvAWnwunSUQzAcGOiMgYrEdK9PauExhc3LozwCrjDH3hbw1DfiZ8/pnwLsHumz7yhhzhzEmxxjTF/s7fG6MuQyYCVzobOaWc9kK5IvIYGfVScBKXPi7YFNCY0Uk0fl7qz8X1/0ujTT3W0wDrnBGD40FyupTSO2ViEwAfg+cbYypDnlrGnCJiMSJSD9sB/i8fTq4MaZT/ANOx/a0/wD8sa3Ls49lPxrb1FsKLHH+nY7NrX8GrHX+m9HWZd3H8zoeeN953d/5480DXgfi2rp8YZ7DCGCB89u8A3Rx6+8C/A34HlgOvAjEuel3AaZg+zf82Kvknzf3W2DTKY869cEy7GipNj+HvZxLHrYvoL4OeCJk+z8657IamLivn6dTTCilVCfXWVJDSimlmqGBQCmlOjkNBEop1clpIFBKqU5OA4FSSnVyGgiUOoBE5Pj6GVeVai80ECilVCengUCpJojI5SIyT0SWiMiTzvMTKkXk/0RkkYh8JiLZzrYjRGROyDzx9XPeHyQin4rId84+A5zDJ4c8w+Bl505epdqMBgKlGhGRocDFwFHGmBFAELgMOxHbImPMKOBL4C/OLi8Avzd2nvhlIetfBh41xgzHzttTP4XBSOAW7LMx+mPnX1KqzUTvfROlOp2TgMOB+c7FegJ2srI64FVnm5eAt0QkDUg3xnzprH8eeF1EUoBexpi3AYwxXgDnePOMMQXO8hKgL/B15E9LqaZpIFBqdwI8b4y5Y5eVIn9utN2e5mfZU7rHF/I6iP5/qNqYpoaU2t1nwIUi0hV2Pve2D/b/l/qZOCcBXxtjyoAdInKMs/6nwJfGPi+iQETOdY4RJyKJB/QslAqTXoko1YgxZqWI/An4RESisDNA/hL74JmDRWQh9gleFzu7/Ax4wqno1wFXOet/CjwpInc5x/jJATwNpcKms48qFSYRqTTGJLd1OZRqbZoaUkqpTk5bBEop1clpi0AppTo5DQRKKdXJaSBQSqlOTgOBUkp1choIlFKqk/t/PxjLIDIfmlcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = Model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary got the milk there . John moved to the bedroom .'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.9999974\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model for first story - to check the predicted accuracy against above element\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
